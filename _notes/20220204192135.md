---
---
# Computer vision - Cameras

Cameras are built trying to imitate how eyes work. Light comes through
an opening, a pinhole or a lens, and hit an image plane where some
photosensitive elements detect it and mesure it.

-   Lens provide more light at the expense of having objects out of
    focus â€“ depth of field.
-   The image plane is divided in pixels, which form the final image
    that has to be processed.

The reduction in hardware and improvements on software have made cameras
a common sensors on the robotics field [20210602191112](/notes/20210602191112).

## Color representation on cameras

The most common way of representing color is **RGB**, representing color
on 3 planes (red, green, blue). However, it has two disadvantages: it is
sensitive to light changes caused by movement and position on the
environment, and also the devices used to capture color are more
insensitive to the red plane than the other two.

**HSI** measures the Hue (dominant wavelength), Saturation (lack of
whiteness) and Intensity (quantity of light received). This deals with
some of the problems of RGB, but are usually more expensive and require
more complex algorithms.

## Notes References

[20210709195051](/notes/20210709195051) INDEX - Computer Vision

[20210602191112](/notes/20210602191112) Cameras and Computer vision in Robotics - Basics

## References

(Murphy 2000)

Murphy, Robin. 2000. *Introduction to AI Robotics*. Intelligent Robotics
and Autonomous Agents. Cambridge, Mass: MIT Press.
